{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import exp\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "import glob2\n",
    "\n",
    "from numba import jit\n",
    "import tables\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import h5py\n",
    "import hdf5storage\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from utility_simulated_drift import (make_shifted_templates,\n",
    "                                      make_default_template,\n",
    "                                      draw_template,\n",
    "                                      gaus,\n",
    "                                      make_drift_template,\n",
    "                                      shift_templates_all,\n",
    "                                      WaveForms,\n",
    "                                      generate_poisson_uniform_firingrate2,\n",
    "                                      select_ground_truth_units,\n",
    "                                      visualize_drift,\n",
    "                                      generate_synthetic_data,\n",
    "                                      visualize_traces,\n",
    "                                      make_full_data)\n",
    "\n",
    "colors = [\n",
    "'black','grey','brown','slategrey',    \n",
    "'orange','firebrick','lawngreen','dodgerblue','crimson','orchid','slateblue',\n",
    "'darkgreen','darkorange','indianred','darkviolet','deepskyblue','greenyellow',\n",
    "'peru','cadetblue','forestgreen','slategrey','lightsteelblue','rebeccapurple',\n",
    "'darkmagenta','yellow','hotpink']\n",
    "clrs= colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth directory already made\n",
      "Total templates avialable;  (575, 101, 384)\n",
      "Total units selected:  100 , ids:  [420 339 421 348 473 418  62 362 565 239] ...\n",
      "templates ground truth:  (100, 101, 384)\n"
     ]
    }
   ],
   "source": [
    "# select working directory location\n",
    "root_dir = '/media/cat/1TB/Dropbox/data_temp/liam/data/neuropixels/run9/'\n",
    "try:\n",
    "    os.mkdir(root_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# set radius of channels to consider from maximum channel outwards (in micrometers)\n",
    "radius = 200\n",
    "\n",
    "# select ground truth templates to be used\n",
    "fname_templates = '/media/cat/1TB/Dropbox/code/neuropixels/allen_inst_2ndrec/templates_reloaded.npy'\n",
    "geom = np.loadtxt('/media/cat/1TB/data/synthetic/p1_g0_t0.imec0.ap_geom.txt')\n",
    "\n",
    "# select largest X templates to be used for injection\n",
    "n_templates = 100\n",
    "(units, templates_ground_truth) = select_ground_truth_units(root_dir, \n",
    "                                                            fname_templates,\n",
    "                                                            n_templates,\n",
    "                                                            geom)\n",
    "\n",
    "print (\"templates ground truth: \", templates_ground_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the desired shifts on a particular unit\n",
    "shifts = np.arange(0, 1., 0.05)\n",
    "\n",
    "# visualize drifted template for any particular unit \n",
    "unit_id = 10\n",
    "visualize_drift(shifts, geom, templates_ground_truth, unit_id,\n",
    "               radius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shifts:  [0.   0.05]\n",
      "(300000, 384)\n",
      "[     0. 300000.]\n",
      "window:  [0.0, 300000.0] , shift:  0.0  (inter channel units)\n",
      " inserting unit:  0 0\n",
      " inserting unit:  50 50\n",
      "************\n",
      "\n",
      "\n",
      "(300000, 384)\n"
     ]
    }
   ],
   "source": [
    "# generate synthetic drift data\n",
    "sample_rate = 30000\n",
    "rec_len_sec = 10\n",
    "rec_length_sample_times = rec_len_sec * sample_rate\n",
    "\n",
    "# spikes, scales = generate_poisson_uniform_firingrate2(rec_length)\n",
    "# setup shifts\n",
    "shifts = np.arange(0, .1, 0.05)\n",
    "print (\"shifts: \", shifts)\n",
    "\n",
    "data_synthetic = generate_synthetic_data(root_dir,\n",
    "                                         rec_len_sec, \n",
    "                                         sample_rate, \n",
    "                                         shifts, \n",
    "                                         units, \n",
    "                                         templates_ground_truth,\n",
    "                                         radius,\n",
    "                                         geom)\n",
    "\n",
    "print (data_synthetic.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the final traces\n",
    "visualize_traces(data_synthetic, 0, 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of correlated noise snipit:  300000\n",
      "self.n_unit, self.n_channel, self.n_time:  100 384 101\n",
      "chan:  0\n",
      "chan:  50\n",
      "chan:  100\n",
      "chan:  150\n"
     ]
    }
   ],
   "source": [
    "# Make a correlated data chunk of 10 seconds \n",
    "# longer takes too long of time; shorter will add more boundary artifcats to recording\n",
    "time = 10*sample_rate\n",
    "print (\"length of correlated noise snipit: \", time)\n",
    "\n",
    "# use ground_truth_templates to make noise\n",
    "temps = templates_ground_truth.copy()\n",
    "WF = WaveForms(temps.transpose(0,2,1))\n",
    "correlated_noise = WF.generate_correlated_noise_add(time)\n",
    "\n",
    "print (\"DONE MAKING CORRELATED NOISE for 10 sec chunk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white noise:  (300000, 384)\n",
      "time chunk:  0  to  300000\n",
      "time chunk:  90000000000  to  90000300000\n",
      "time chunk:  180000000000  to  180000300000\n",
      "time chunk:  270000000000  to  270000300000\n",
      "time chunk:  360000000000  to  360000300000\n",
      "time chunk:  450000000000  to  450000300000\n"
     ]
    }
   ],
   "source": [
    "# blend correlated noise with injected spike dataset\n",
    "data_sum = make_full_data(data_synthetic, rec_length_sample_times, \n",
    "                          sample_rate, root_dir,\n",
    "                          correlated_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize first 10000 time points;\n",
    "visualize_traces(data_sum, 0, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
