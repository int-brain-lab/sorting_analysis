{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import exp\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "import glob2\n",
    "\n",
    "from numba import jit\n",
    "import tables\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import h5py\n",
    "import hdf5storage\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from utility_simulated_drift import (make_shifted_templates,\n",
    "                                      make_default_template,\n",
    "                                      draw_template,\n",
    "                                      gaus,\n",
    "                                      make_drift_template,\n",
    "                                      shift_templates_all,\n",
    "                                      WaveForms,\n",
    "                                      generate_poisson_uniform_firingrate2,\n",
    "                                      select_ground_truth_units,\n",
    "                                      visualize_drift,\n",
    "                                      generate_synthetic_data,\n",
    "                                      visualize_traces,\n",
    "                                      make_full_data)\n",
    "\n",
    "colors = [\n",
    "'black','grey','brown','slategrey',    \n",
    "'orange','firebrick','lawngreen','dodgerblue','crimson','orchid','slateblue',\n",
    "'darkgreen','darkorange','indianred','darkviolet','deepskyblue','greenyellow',\n",
    "'peru','cadetblue','forestgreen','slategrey','lightsteelblue','rebeccapurple',\n",
    "'darkmagenta','yellow','hotpink']\n",
    "clrs= colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth directory already made\n",
      "Total templates avialable;  (575, 101, 384)\n",
      "Total units selected:  100 , ids:  [420 339 421 348 473 418  62 362 565 239] ...\n",
      "templates ground truth:  (100, 101, 384)\n"
     ]
    }
   ],
   "source": [
    "# select working directory location\n",
    "root_dir = '/media/cat/1TB/data/synthetic/run11/'\n",
    "try:\n",
    "    os.mkdir(root_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# set radius of channels to consider from maximum channel outwards (in micrometers)\n",
    "radius = 200\n",
    "\n",
    "# select ground truth templates to be used\n",
    "#fname_templates = '/media/cat/12TB/dbox/Dropbox/code/neuropixels/allen_inst_2ndrec/templates_reloaded.npy'\n",
    "#geom = np.loadtxt('/home/cat/p1_g0_t0.imec0.ap_geom_384chans.txt')\n",
    "fname_templates = '/media/cat/1TB/data/synthetic/allen_inst_2ndrec/templates_reloaded.npy'\n",
    "geom = np.loadtxt('/media/cat/1TB/data/synthetic/p1_g0_t0.imec0.ap_geom.txt')\n",
    "\n",
    "\n",
    "\n",
    "# select largest X templates to be used for injection\n",
    "n_templates = 100\n",
    "(units, templates_ground_truth) = select_ground_truth_units(root_dir, \n",
    "                                                            fname_templates,\n",
    "                                                            n_templates,\n",
    "                                                            geom)\n",
    "\n",
    "print (\"templates ground truth: \", templates_ground_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the desired shifts on a particular unit\n",
    "shifts = np.arange(0, 1., 0.05)\n",
    "\n",
    "# visualize drifted template for any particular unit \n",
    "unit_id = 10\n",
    "visualize_drift(shifts, geom, templates_ground_truth, unit_id,\n",
    "               radius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shifts:  [0.   0.05]\n",
      "(300000, 384)\n",
      "[     0. 300000.]\n",
      "window:  [0.0, 300000.0] , shift:  0.0  (inter channel units)\n",
      " inserting unit:  0 0\n",
      " inserting unit:  50 50\n",
      "************\n",
      "\n",
      "\n",
      "(300000, 384)\n"
     ]
    }
   ],
   "source": [
    "# generate synthetic drift data\n",
    "sample_rate = 30000\n",
    "rec_len_sec = 10\n",
    "rec_length_sample_times = rec_len_sec * sample_rate\n",
    "\n",
    "# spikes, scales = generate_poisson_uniform_firingrate2(rec_length)\n",
    "# setup shifts\n",
    "shifts = np.arange(0, .1, 0.05)\n",
    "print (\"shifts: \", shifts)\n",
    "\n",
    "data_synthetic = generate_synthetic_data(root_dir,\n",
    "                                         rec_len_sec, \n",
    "                                         sample_rate, \n",
    "                                         shifts, \n",
    "                                         units, \n",
    "                                         templates_ground_truth,\n",
    "                                         radius,\n",
    "                                         geom)\n",
    "\n",
    "np.savetxt(root_dir+'/ground_truth/shifts.txt', shifts)\n",
    "print (data_synthetic.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the final traces\n",
    "visualize_traces(data_synthetic, 0, 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of correlated noise snipit:  300000\n"
     ]
    }
   ],
   "source": [
    "# Make a correlated data chunk of 10 seconds \n",
    "# longer takes too long of time; shorter will add more boundary artifcats to recording\n",
    "time = 10*sample_rate\n",
    "print (\"length of correlated noise snipit: \", time)\n",
    "\n",
    "fname = root_dir+'correlated_noise.npy'\n",
    "# use ground_truth_templates to make noise\n",
    "if os.path.exists(fname)==False:\n",
    "    temps = templates_ground_truth.copy()\n",
    "    WF = WaveForms(temps.transpose(0,2,1))\n",
    "    correlated_noise = WF.generate_correlated_noise_add(time)\n",
    "\n",
    "    print (\"DONE MAKING CORRELATED NOISE for 10 sec chunk\")\n",
    "    \n",
    "    np.save(fname, correlated_noise)\n",
    "else:\n",
    "    correlated_noise = np.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white noise:  (300000, 384)\n",
      "time chunk:  0  to  300000\n"
     ]
    }
   ],
   "source": [
    "# blend correlated noise with injected spike dataset\n",
    "data_sum = make_full_data(data_synthetic, rec_length_sample_times, \n",
    "                          sample_rate, root_dir,\n",
    "                          correlated_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize first 10000 time points;\n",
    "visualize_traces(data_sum, 0, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize spike triggered max chan data\n",
    "spike_train_gt = np.load('/media/cat/1TB/data/synthetic/run11/ground_truth/spike_train_ground_truth.npy')\n",
    "fname= '/media/cat/1TB/data/synthetic/run11/data_int16.bin'\n",
    "\n",
    "from utility_match_units import binary_reader_waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 101, 384)\n"
     ]
    }
   ],
   "source": [
    "n_channels = 384\n",
    "n_times = 101\n",
    "\n",
    "# \n",
    "units = np.arange(25)\n",
    "units = [13]\n",
    "for unit in units:\n",
    "    #ax=plt.subplot(5,5,unit+1)\n",
    "    idx = np.where(spike_train_gt[:,1]==unit)[0]\n",
    "    spikes = spike_train_gt[idx,0]\n",
    "    wfs = binary_reader_waveforms(fname, n_channels, n_times, spikes, data_type='int16')\n",
    "\n",
    "    print (wfs.shape)\n",
    "    max_chan = wfs.mean(0).ptp(0).argmax(0)\n",
    "\n",
    "    #fig=plt.figure()\n",
    "    plt.plot(wfs[:,:,max_chan].T,c='black')\n",
    "    plt.show()\n",
    "\n",
    "    if True:\n",
    "        fig=plt.figure()\n",
    "        for k in range(wfs.shape[0]):\n",
    "            ax=plt.subplot(10,10,k+1)\n",
    "            plt.plot(wfs[k,:,max_chan].T,c='black')\n",
    "            plt.title(str(k)+\" \"+str(spikes[k]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85,)\n",
      "(85,)\n",
      "[1.         0.69767633 0.64403642 1.         1.         0.99501248\n",
      " 0.74453159 0.71177032 0.68045064 1.         1.         0.89136614\n",
      " 0.79057085 1.         1.         1.         0.68728928 1.\n",
      " 0.81873075 1.         1.         0.93706746 0.86070798 0.83945702\n",
      " 1.         0.97044553 0.72614904 0.86935824 0.85641518 0.98019867\n",
      " 1.         0.66034028 1.         0.62188506 1.         0.99004983\n",
      " 0.69073433 0.77105159 0.83110428 0.70117344 1.         0.99004983\n",
      " 1.         0.88692044 0.81058425 1.         0.61878339 0.92774349\n",
      " 1.         0.63762815 1.         0.6156972  1.         1.\n",
      " 0.68728928 0.78662786 1.         0.60957091 0.60957091 0.77880078\n",
      " 0.85214379 1.         1.         1.         1.         0.72614904\n",
      " 0.70117344 1.         1.         1.         0.66697681 0.99501248\n",
      " 1.         1.         0.62188506 0.81873075 0.62500227 0.66034028\n",
      " 0.65376979 1.         0.82695913 0.64082428 0.64082428 1.\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "times = np.load('/media/cat/1TB/temp/'+str(unit)+'_times.npy')\n",
    "scale = np.load('/media/cat/1TB/temp/'+str(unit)+'_scale.npy')\n",
    "\n",
    "print (times.shape)\n",
    "print (scale.shape)\n",
    "print (scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
